# _FinanceFlow_ #

A small scale data engineering project. The aim of this project is for me to learn foundational data engineering concepts and put them into practice.  
Project is divided into 4 different phases with each phase having a set of deliverables: 

## Phase 1: ETL & Data Pipeline Setup (Foundation) ## 
Deliverables:

Database Infrastructure

* PostgreSQL database setup
* Optimized schema design
* Basic data validation checks
* Error logging system


Data Extraction System

* YFinance API integration
* Data quality checks
* Basic error handling
* Data transformation logic


Initial Codebase

* Organized project structure
* Production-ready scripts
* Basic documentation
* Unit tests



## Phase 2: Pipeline Automation (Orchestration) ##
Deliverables:

Airflow Setup

* Local Airflow installation
* Basic DAG creation
* Scheduled data updates
* Pipeline monitoring


Enhanced ETL

* Automated data validation
* Error notification system
* Retry mechanisms
* Data backfill capabilities


Data Quality

* Validation rules
* Data freshness checks
* Duplicate handling
* Missing data management



## Phase 3: Machine Learning Integration ##
Deliverables:

Data Preparation

* Feature engineering pipeline
* Data preprocessing steps
* Training/test split logic
* Feature validation


Model Development

* ARIMA implementation
* LSTM implementation
* Model validation framework
* Prediction pipeline


Model Management

* Model versioning
* Performance monitoring
* Automated retraining
* Prediction storage



## Phase 4: Dashboard & Optimization ##
Deliverables:

Dashboard Development

* Streamlit interface
* Interactive visualizations
* Real-time updates
* User-friendly controls


Performance Optimization

* Query optimization
* Database indexing
* Caching implementation
* Response time improvements


Documentation & Deployment

* System architecture docs
* API documentation
* User guides
* Maintenance procedures 

Depending on time constraints, deliverables may be omitted or added as project progresses. 
